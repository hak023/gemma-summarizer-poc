import json
import re
from typing import Dict, Any, Optional

class ResponsePostprocessor:
    """Gemma ì‘ë‹µ ë°ì´í„° í›„ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    def select_best_sentence(sentences: list) -> str:
        """
        ì—¬ëŸ¬ ë¬¸ì¥ ì¤‘ì—ì„œ ê°€ì¥ ì í•©í•œ ë¬¸ì¥ì„ ì„ íƒ
        ê°€ì¤‘ì¹˜ ê¸°ì¤€: ê¸¸ì´, í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€, ëª…í™•ì„±
        """
        if not sentences:
            return ""
        
        if len(sentences) == 1:
            return sentences[0]
        
        # ê° ë¬¸ì¥ì˜ ì ìˆ˜ ê³„ì‚°
        sentence_scores = []
        for sentence in sentences:
            score = 0
            
            # 1. ê¸¸ì´ ì ìˆ˜ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ê²ƒ ì œì™¸)
            length = len(sentence.strip())
            if 10 <= length <= 50:
                score += 3
            elif 5 <= length <= 80:
                score += 2
            else:
                score += 1
            
            # 2. í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì ìˆ˜
            keywords = ['ë¬¸ì˜', 'ë‹µë³€', 'ì•ˆë‚´', 'ì„¤ëª…', 'ì²˜ë¦¬', 'í•´ê²°', 'í™•ì¸', 'ê²€í† ', 'ë¶„ì„']
            for keyword in keywords:
                if keyword in sentence:
                    score += 2
                    break
            
            # 3. ëª…í™•ì„± ì ìˆ˜ (êµ¬ì²´ì ì¸ ë™ì‚¬ í¬í•¨)
            action_words = ['ë¬¸ì˜', 'ë‹µë³€', 'ì•ˆë‚´', 'ì„¤ëª…', 'ì²˜ë¦¬', 'í•´ê²°', 'í™•ì¸', 'ê²€í† ', 'ë¶„ì„', 'ì œê³µ', 'ë°œê¸‰', 'ì´ìš©']
            for word in action_words:
                if word in sentence:
                    score += 1
            
            # 4. ë¶€ì •ì  í‘œí˜„ ì œì™¸
            negative_words = ['ë¶ˆê°€ëŠ¥', 'ë¶ˆê°€', 'ì˜¤ë¥˜', 'ì˜¤ë¥˜', 'ì‹¤íŒ¨', 'ì‹¤íŒ¨', 'ë¬¸ì œ', 'ë¬¸ì œ']
            for word in negative_words:
                if word in sentence:
                    score -= 1
            
            sentence_scores.append((sentence, score))
        
        # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ë¬¸ì¥ ì„ íƒ
        best_sentence = max(sentence_scores, key=lambda x: x[1])
        return best_sentence[0]
    
    @staticmethod
    def convert_to_noun_form(text: str) -> str:
        """
        ë™ì‚¬í˜• ì¢…ê²°ì–´ë¥¼ ëª…ì‚¬í˜•ìœ¼ë¡œ ë³€í™˜
        ì˜ˆ: "ì•ˆë‚´í–ˆìŠµë‹ˆë‹¤" â†’ "ì•ˆë‚´", "ì²˜ë¦¬ë©ë‹ˆë‹¤" â†’ "ì²˜ë¦¬"
        """
        if not text:
            return text
        
        text = text.strip()
        
        # ë™ì‚¬í˜• ì¢…ê²°ì–´ íŒ¨í„´ê³¼ ëŒ€ì‘í•˜ëŠ” ëª…ì‚¬í˜• ë§¤í•‘
        verb_to_noun_patterns = [
            # íŠ¹ì • ë™ì‚¬ â†’ ëª…ì‚¬ ë³€í™˜
            (r'(.+?)ì•ˆë‚´í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì•ˆë‚´'),
            (r'(.+?)í™•ì¸í–ˆìŠµë‹ˆë‹¤\.?$', r'\1í™•ì¸'),
            (r'(.+?)ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì²˜ë¦¬'),
            (r'(.+?)ì§„í–‰í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì§„í–‰'),
            (r'(.+?)ì™„ë£Œí–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì™„ë£Œ'),
            (r'(.+?)ì œê³µí–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì œê³µ'),
            (r'(.+?)ë°œê¸‰í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ë°œê¸‰'),
            (r'(.+?)ì„¤ëª…í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì„¤ëª…'),
            (r'(.+?)ìš”ì²­í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ìš”ì²­'),
            (r'(.+?)ì ‘ìˆ˜í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì ‘ìˆ˜'),
            (r'(.+?)ê²€í† í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ê²€í† '),
            (r'(.+?)ìŠ¹ì¸í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ìŠ¹ì¸'),
            (r'(.+?)ì‹ ì²­í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ì‹ ì²­'),
            (r'(.+?)ë…¼ì˜í–ˆìŠµë‹ˆë‹¤\.?$', r'\1ë…¼ì˜'),
            
            # ìˆ˜ë™í˜• â†’ ëª…ì‚¬ ë³€í™˜
            (r'(.+?)ì•ˆë‚´ë©ë‹ˆë‹¤\.?$', r'\1ì•ˆë‚´'),
            (r'(.+?)í™•ì¸ë©ë‹ˆë‹¤\.?$', r'\1í™•ì¸'),
            (r'(.+?)ì²˜ë¦¬ë©ë‹ˆë‹¤\.?$', r'\1ì²˜ë¦¬'),
            (r'(.+?)ì§„í–‰ë©ë‹ˆë‹¤\.?$', r'\1ì§„í–‰'),
            (r'(.+?)ì™„ë£Œë©ë‹ˆë‹¤\.?$', r'\1ì™„ë£Œ'),
            (r'(.+?)ì œê³µë©ë‹ˆë‹¤\.?$', r'\1ì œê³µ'),
            (r'(.+?)ë°œê¸‰ë©ë‹ˆë‹¤\.?$', r'\1ë°œê¸‰'),
            (r'(.+?)ë°œìƒë©ë‹ˆë‹¤\.?$', r'\1ë°œìƒ'),
            (r'(.+?)ì§€ê¸‰ë©ë‹ˆë‹¤\.?$', r'\1ì§€ê¸‰'),
            (r'(.+?)ì‚¬ìš©ë©ë‹ˆë‹¤\.?$', r'\1ì‚¬ìš©'),
            (r'(.+?)ê²°ì œë©ë‹ˆë‹¤\.?$', r'\1ê²°ì œ'),
            (r'(.+?)ì·¨ì†Œë©ë‹ˆë‹¤\.?$', r'\1ì·¨ì†Œ'),
            (r'(.+?)ì—°ê²°ë©ë‹ˆë‹¤\.?$', r'\1ì—°ê²°'),
            (r'(.+?)ë“±ë¡ë©ë‹ˆë‹¤\.?$', r'\1ë“±ë¡'),
            (r'(.+?)ì´ë£¨ì–´ì§‘ë‹ˆë‹¤\.?$', r'\1 ì§„í–‰'),
            
            # ë‹¨ìˆœ ì¢…ê²°ì–´ ì œê±°
            (r'(.+?)í–ˆìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë©ë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë°›ì•˜ìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë“œë ¸ìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë³´ì˜€ìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)í¬í•¨ë©ë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ê°€ëŠ¥í•©ë‹ˆë‹¤\.?$', r'\1ê°€ëŠ¥'),
            (r'(.+?)í•©ë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ì…ë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ì—†ì—ˆìŠµë‹ˆë‹¤\.?$', r'\1 ì—†ìŒ'),
            (r'(.+?)ìˆì—ˆìŠµë‹ˆë‹¤\.?$', r'\1 ìˆìŒ'),
            (r'(.+?)ë˜ì—ˆìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë˜ì–´ìˆìŠµë‹ˆë‹¤\.?$', r'\1'),
            (r'(.+?)ë˜ì–´ ìˆìŠµë‹ˆë‹¤\.?$', r'\1'),
            
            # ê¸°íƒ€ íŒ¨í„´
            (r'(.+?)ì— ëŒ€í•œ (.+?)$', r'\1 \2'),  # "~ì— ëŒ€í•œ" ê°„ì†Œí™”
            (r'(.+?)ì— ê´€í•œ (.+?)$', r'\1 \2'),  # "~ì— ê´€í•œ" ê°„ì†Œí™”
        ]
        
        # íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë³€í™˜
        for pattern, replacement in verb_to_noun_patterns:
            new_text = re.sub(pattern, replacement, text)
            if new_text != text:
                text = new_text.strip()
                break
        
        # ì—°ì†ëœ ê³µë°± ì •ë¦¬
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    @staticmethod
    def extract_first_sentence(text: str) -> str:
        """
        ì…ë ¥ í…ìŠ¤íŠ¸ì—ì„œ ì²« ë²ˆì§¸ ë¬¸ì¥ë§Œ ì¶”ì¶œí•˜ì—¬ ë°˜í™˜
        - í•œêµ­ì–´/ì˜ë¬¸ ê³µí†µ ë¬¸ì¥ ì¢…ê²°ë¶€í˜¸(. ! ?) ë° ìœ ì‚¬ ê¸°í˜¸(ã€‚ ï¼ ï¼Ÿ) ê¸°ì¤€
        - ì¢…ê²°ë¶€í˜¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ë°˜í™˜
        """
        if not text:
            return ""
        text = text.strip()
        match = re.search(r'^(.+?[\.!?ã€‚ï¼ï¼Ÿ])', text)
        if match:
            return match.group(1).strip()
        return text
    
    @staticmethod
    def process_summary(value: str) -> str:
        """
        summary í•„ë“œ í›„ì²˜ë¦¬
        - ì˜ˆì‹œ ë‚´ìš© í•„í„°ë§
        - 80 byte ì´ˆê³¼ ì‹œ ì¬ì§ˆì˜ í•„ìš” í‘œì‹œ
        - ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        """
        if not value:
            return "ìš”ì•½ì´ ë¶ˆê°€ëŠ¥í•œ ë‚´ìš©ì…ë‹ˆë‹¤."
        
        # ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
        if not isinstance(value, str):
            value = str(value)
        
        # ì´ë¯¸ [ì¬ì§ˆì˜ í•„ìš”] í‘œì‹œê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        if value.startswith('[ì¬ì§ˆì˜ í•„ìš”]'):
            return value
        
        # ì˜ˆì‹œ ë‚´ìš© í•„í„°ë§
        example_patterns = [
            r'ì˜ˆì‹œ.*ë‚´ìš©',
            r'ìƒ˜í”Œ.*ë‚´ìš©',
            r'í…ŒìŠ¤íŠ¸.*ë‚´ìš©',
            r'ì¶œë ¥.*ì˜ˆì‹œ',
            r'ë¶„ì„.*ê·œì¹™',
            r'ì¶œë ¥.*í˜•ì‹',
            r'```json',
            r'```',
            r'JSON.*í˜•ì‹',
            r'ë‹¤ìŒ.*í˜•ì‹'
        ]
        
        is_example = False
        for pattern in example_patterns:
            if re.search(pattern, value, re.IGNORECASE):
                is_example = True
                break
        
        if is_example:
            return "ìš”ì•½ ì—†ìŒ"
        
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        cleaned = re.sub(r'\s+', ' ', value.strip())
        
        # ë™ì‚¬í˜•ì„ ëª…ì‚¬í˜•ìœ¼ë¡œ ë³€í™˜
        original_cleaned = cleaned
        cleaned = ResponsePostprocessor.convert_to_noun_form(cleaned)
        if original_cleaned != cleaned:
            print(f"ğŸ“ convert_to_noun_form ì ìš©: '{original_cleaned}' â†’ '{cleaned}'")
        else:
            print(f"ğŸ“ convert_to_noun_form ë³€ê²½ ì—†ìŒ: '{cleaned}'")
        
        # 120 byte ì´ˆê³¼ ì‹œ ì¬ì§ˆì˜ í•„ìš” í‘œì‹œ (í•œê¸€ ê¸°ì¤€ ì•½ 40ì)
        if len(cleaned.encode('utf-8')) > 120:
            return f"[ì¬ì§ˆì˜ í•„ìš”] {cleaned}"
        
        return cleaned
    
    @staticmethod
    def process_keywords(value: str) -> str:
        """
        keyword í•„ë“œ í›„ì²˜ë¦¬
        - ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œ ì •ë¦¬
        - ì¤‘ë³µ ì œê±°
        - 5ê°œë¡œ ì œí•œ
        """
        if not value:
            return "í‚¤ì›Œë“œ ì—†ìŒ"
        
        # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(value, list):
            keywords = [str(kw).strip() for kw in value if kw and str(kw).strip()]
        else:
            # ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
            value = str(value)
            # ë¬¸ìì—´ì¸ ê²½ìš° ì‰¼í‘œë¡œ ë¶„ë¦¬
            keywords = [kw.strip() for kw in value.split(',') if kw.strip()]
        
        # ì¤‘ë³µ ì œê±°
        unique_keywords = list(dict.fromkeys(keywords))
        
        # 5ê°œë¡œ ì œí•œ
        if len(unique_keywords) > 5:
            unique_keywords = unique_keywords[:5]
        
        return ', '.join(unique_keywords)
    
    @staticmethod
    def process_paragraphs(paragraphs: list) -> list:
        """
        paragraphs í•„ë“œ í›„ì²˜ë¦¬
        - ê° paragraphì˜ ì˜ˆì‹œ ë‚´ìš© í•„í„°ë§
        - sentiment ê°’ ì •ê·œí™”
        - paragraphsì˜ summaryëŠ” ì¬ì§ˆì˜ ë¡œì§ ì œì™¸
        - paragraphsì˜ summaryëŠ” ìµœê³  ë¬¸ì¥(select_best_sentence)ë§Œ ì‚¬ìš©
        """
        if not paragraphs or not isinstance(paragraphs, list):
            return []
        
        processed_paragraphs = []
        
        for paragraph in paragraphs:
            if not isinstance(paragraph, dict):
                continue
                
            processed_para = {}
            
            # summary ì²˜ë¦¬ (paragraphsì˜ summaryëŠ” ì¬ì§ˆì˜ ë¡œì§ ì œì™¸)
            summary = paragraph.get('summary', '')
            if summary:
                # ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
                if not isinstance(summary, str):
                    summary = str(summary)
                
                # ì˜ˆì‹œ ë‚´ìš© í•„í„°ë§
                example_patterns = [
                    r'ì˜ˆì‹œ.*ë‚´ìš©',
                    r'ìƒ˜í”Œ.*ë‚´ìš©',
                    r'í…ŒìŠ¤íŠ¸.*ë‚´ìš©',
                    r'ì¶œë ¥.*ì˜ˆì‹œ',
                    r'ë¶„ì„.*ê·œì¹™',
                    r'ì¶œë ¥.*í˜•ì‹'
                ]
                
                is_example = False
                for pattern in example_patterns:
                    if re.search(pattern, summary, re.IGNORECASE):
                        is_example = True
                        break
                
                if is_example:
                    summary = "ë¬¸ë‹¨ ìš”ì•½ ì—†ìŒ"
                
                cleaned_summary = re.sub(r'\s+', ' ', summary.strip())
                # ë¬¸ì¥ ë¶„ë¦¬ í›„ ìµœê³  ë¬¸ì¥ ì„ íƒ
                sentences = [s.strip() for s in re.split(r'(?<=[\.!?ã€‚ï¼ï¼Ÿ])\s+', cleaned_summary) if s.strip()]
                if not sentences:
                    sentences = [cleaned_summary]
                best_sentence = ResponsePostprocessor.select_best_sentence(sentences)
                # ë™ì‚¬í˜•ì„ ëª…ì‚¬í˜•ìœ¼ë¡œ ë³€í™˜
                original_sentence = best_sentence
                best_sentence = ResponsePostprocessor.convert_to_noun_form(best_sentence)
                if original_sentence != best_sentence:
                    print(f"ğŸ“ paragraph convert_to_noun_form ì ìš©: '{original_sentence}' â†’ '{best_sentence}'")
                else:
                    print(f"ğŸ“ paragraph convert_to_noun_form ë³€ê²½ ì—†ìŒ: '{best_sentence}'")
                processed_para['summary'] = best_sentence
            else:
                processed_para['summary'] = "ë¬¸ë‹¨ ìš”ì•½ ì—†ìŒ"
            
            # keyword ì²˜ë¦¬
            keyword = paragraph.get('keyword', '')
            if keyword:
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë³€í™˜
                if isinstance(keyword, list):
                    keyword = ', '.join([str(kw).strip() for kw in keyword if kw and str(kw).strip()])
                elif not isinstance(keyword, str):
                    keyword = str(keyword)
                
                # ì˜ˆì‹œ ë‚´ìš© í•„í„°ë§
                example_patterns = [
                    r'ì˜ˆì‹œ.*í‚¤ì›Œë“œ',
                    r'ìƒ˜í”Œ.*í‚¤ì›Œë“œ',
                    r'í…ŒìŠ¤íŠ¸.*í‚¤ì›Œë“œ',
                    r'ì¶œë ¥.*ì˜ˆì‹œ',
                    r'ë¶„ì„.*ê·œì¹™',
                    r'ì¶œë ¥.*í˜•ì‹'
                ]
                
                is_example = False
                for pattern in example_patterns:
                    if re.search(pattern, keyword, re.IGNORECASE):
                        is_example = True
                        break
                
                if is_example:
                    keyword = "í‚¤ì›Œë“œ ì—†ìŒ"
                
                processed_para['keyword'] = re.sub(r'\s+', ' ', keyword.strip())
            else:
                processed_para['keyword'] = "í‚¤ì›Œë“œ ì—†ìŒ"
            
            # sentiment ì²˜ë¦¬
            sentiment = paragraph.get('sentiment', '')
            if sentiment:
                # ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ë¬¸ìì—´ë¡œ ë³€í™˜
                if not isinstance(sentiment, str):
                    sentiment = str(sentiment)
                
                # ìƒˆë¡œìš´ ê°ì • ê°’ìœ¼ë¡œ ì •ê·œí™”
                sentiment_mapping = {
                    'ê°•í•œê¸ì •': 'ê°•í•œê¸ì •',
                    'ì•½í•œê¸ì •': 'ì•½í•œê¸ì •',
                    'ë³´í†µ': 'ë³´í†µ',
                    'ì•½í•œë¶€ì •': 'ì•½í•œë¶€ì •',
                    'ê°•í•œë¶€ì •': 'ê°•í•œë¶€ì •',
                    # ê¸°ì¡´ ê°ì • ê°’ ë§¤í•‘
                    'ê¸ì •': 'ì•½í•œê¸ì •',
                    'ë¶€ì •': 'ì•½í•œë¶€ì •',
                    'ì¤‘ë¦½': 'ë³´í†µ',
                    'ë§Œì¡±': 'ì•½í•œê¸ì •',
                    'ë¶ˆë§Œ': 'ì•½í•œë¶€ì •',
                    'í™”ë‚¨': 'ê°•í•œë¶€ì •',
                    'ì‹ ë‚¨': 'ì•½í•œê¸ì •',
                    'ìš°ë ¤': 'ì•½í•œë¶€ì •'
                }
                
                processed_para['sentiment'] = sentiment_mapping.get(sentiment, 'ë³´í†µ')
            else:
                processed_para['sentiment'] = 'ë³´í†µ'
            
            processed_paragraphs.append(processed_para)
        
        return processed_paragraphs
    
    @classmethod
    def process_response(cls, response_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì „ì²´ ì‘ë‹µ ë°ì´í„° í›„ì²˜ë¦¬
        
        Args:
            response_data (Dict[str, Any]): ì›ë³¸ ì‘ë‹µ ë°ì´í„°
            
        Returns:
            Dict[str, Any]: í›„ì²˜ë¦¬ëœ ì‘ë‹µ ë°ì´í„°
        """
        try:
            # JSON ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹±
            if isinstance(response_data, str):
                response_data = json.loads(response_data)
            
            # response_dataê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ê¸°ë³¸ê°’ ë°˜í™˜
            if not isinstance(response_data, dict):
                print(f"ì‘ë‹µ ë°ì´í„°ê°€ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹™ë‹ˆë‹¤: {type(response_data)}")
                return {
                    'summary': 'í†µí™” ë‚´ìš© ìš”ì•½ ì—†ìŒ',
                    'keyword': 'í‚¤ì›Œë“œ ì—†ìŒ',
                    'paragraphs': []
                }
            
            processed_data = {}
            
            # í˜„ì¬ JSON êµ¬ì¡° ì²˜ë¦¬ (summary, keyword, paragraphs)
            if 'summary' in response_data and 'keyword' in response_data and 'paragraphs' in response_data:
                # í˜„ì¬ êµ¬ì¡°ì— ë§ëŠ” í›„ì²˜ë¦¬
                processed_data['summary'] = cls.process_summary(response_data.get('summary', ''))
                processed_data['keyword'] = cls.process_keywords(response_data.get('keyword', ''))
                paragraphs = response_data.get('paragraphs', [])
                
                # paragraphsê°€ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ ì„¤ì • (2-3ê°œ)
                if not paragraphs or not isinstance(paragraphs, list) or len(paragraphs) == 0:
                    paragraphs = [
                        {
                            'summary': 'ìš”ì•½ì´ ë¶ˆê°€ëŠ¥í•œ ë‚´ìš©ì…ë‹ˆë‹¤.'
                        }
                    ]
                
                processed_data['paragraphs'] = cls.process_paragraphs(paragraphs)
                
                return processed_data
            
            # ê¸°ì¡´ êµ¬ì¡°ê°€ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"í˜„ì¬ êµ¬ì¡°ê°€ ì•„ë‹Œ ì‘ë‹µ ë°ì´í„°: {list(response_data.keys())}")
            return {
                'summary': 'í†µí™” ë‚´ìš© ìš”ì•½ ì—†ìŒ',
                'keyword': 'í‚¤ì›Œë“œ ì—†ìŒ',
                'paragraphs': []
            }
            
        except Exception as e:
            print(f"í›„ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                'summary': 'í†µí™” ë‚´ìš© ìš”ì•½ ì—†ìŒ',
                'keyword': 'í‚¤ì›Œë“œ ì—†ìŒ',
                'paragraphs': []
            }
    
    @classmethod
    def process_response_to_json(cls, response_data: Dict[str, Any]) -> str:
        """
        ì‘ë‹µ ë°ì´í„° í›„ì²˜ë¦¬ í›„ JSON ë¬¸ìì—´ë¡œ ë°˜í™˜
        
        Args:
            response_data (Dict[str, Any]): ì›ë³¸ ì‘ë‹µ ë°ì´í„°
            
        Returns:
            str: í›„ì²˜ë¦¬ëœ JSON ë¬¸ìì—´
        """
        processed_data = cls.process_response(response_data)
        return json.dumps(processed_data, ensure_ascii=False, indent=2)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("=== ì‘ë‹µ í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    
    # í…ŒìŠ¤íŠ¸ìš© ì‘ë‹µ ë°ì´í„° (í˜„ì¬ êµ¬ì¡°)
    test_response = {
        "summary": "ê³ ê°ì´ ë°”ìš°ì²˜ ì¹´ë“œ ì‚¬ìš© ë¬¸ì˜ë¥¼ í•˜ê³  ìƒë‹´ì›ì´ ìƒì„¸íˆ ë‹µë³€í–ˆìŠµë‹ˆë‹¤.",
        "keyword": "ë°”ìš°ì²˜, ì¹´ë“œ, ì‚¬ìš©, ë¬¸ì˜, ìƒë‹´",
        "paragraphs": [
            {
                "summary": "ë°”ìš°ì²˜ ì¹´ë“œ ì‚¬ìš© ë¬¸ì˜",
                "keyword": "ë°”ìš°ì²˜, ì¹´ë“œ, ë¬¸ì˜",
                "sentiment": "ë³´í†µ"
            },
            {
                "summary": "ìƒë‹´ì› ìƒì„¸ ë‹µë³€",
                "keyword": "ìƒë‹´, ë‹µë³€, ì•ˆë‚´",
                "sentiment": "ì•½í•œê¸ì •"
            }
        ]
    }
    
    print("ì›ë³¸ ë°ì´í„°:")
    print(json.dumps(test_response, ensure_ascii=False, indent=2))
    
    print("\ní›„ì²˜ë¦¬ëœ ë°ì´í„°:")
    processed = ResponsePostprocessor.process_response(test_response)
    print(json.dumps(processed, ensure_ascii=False, indent=2))
    
    print("\n=== ê°œë³„ í•„ë“œ í…ŒìŠ¤íŠ¸ ===")
    print(f"summary: '{test_response['summary']}' -> '{ResponsePostprocessor.process_summary(test_response['summary'])}'")
    print(f"keyword: '{test_response['keyword']}' -> '{ResponsePostprocessor.process_keywords(test_response['keyword'])}'")
    
    print("\n=== 60 byte ì´ˆê³¼ í…ŒìŠ¤íŠ¸ ===")
    long_summary = "ê³ ê°ì´ ë°”ìš°ì²˜ ì¹´ë“œ ì‚¬ìš©ë²•ì— ëŒ€í•´ ë§¤ìš° ìƒì„¸í•˜ê²Œ ë¬¸ì˜ë¥¼ í–ˆê³ , ìƒë‹´ì›ì´ ëª¨ë“  ì ˆì°¨ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ë“œë ¸ìœ¼ë©°, ê³ ê°ì´ ì™„ì „íˆ ë§Œì¡±ìŠ¤ëŸ¬ì›Œí–ˆìŠµë‹ˆë‹¤."
    print(f"ê¸´ ìš”ì•½: '{long_summary}'")
    print(f"ì²˜ë¦¬ ê²°ê³¼: '{ResponsePostprocessor.process_summary(long_summary)}'")
    print(f"ë°”ì´íŠ¸ ê¸¸ì´: {len(long_summary.encode('utf-8'))}")
    
    print("\n=== ë‹¤ì¤‘ ë¬¸ì¥ ê°€ì¤‘ì¹˜ ë¹„êµ í…ŒìŠ¤íŠ¸ ===")
    multi_sentence_tests = [
        "ê³ ê°ì´ ë°”ìš°ì²˜ ì¹´ë“œ ì‚¬ìš©ë²•ì„ ë¬¸ì˜í–ˆìŠµë‹ˆë‹¤. ìƒë‹´ì›ì´ ìƒì„¸íˆ ë‹µë³€í–ˆìŠµë‹ˆë‹¤. ê³ ê°ì´ ë§Œì¡±í–ˆìŠµë‹ˆë‹¤.",
        "ì‹œìŠ¤í…œ ì ê²€ ì¤‘ì…ë‹ˆë‹¤. ì„œë¹„ìŠ¤ê°€ ì¼ì‹œ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë¹ ë¥¸ ë³µêµ¬ë¥¼ ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
        "ë°”ìš°ì²˜ ì¹´ë“œ ë°œê¸‰ ì ˆì°¨ë¥¼ ì•ˆë‚´í–ˆìŠµë‹ˆë‹¤. ê³ ê°ì´ ì´í•´í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ë¬¸ì˜ì‚¬í•­ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.",
        "ê³ ê°ì´ ë¶ˆë§Œì„ ì œê¸°í–ˆìŠµë‹ˆë‹¤. ìƒë‹´ì›ì´ ì‚¬ê³¼í–ˆìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ í•´ê²°í–ˆìŠµë‹ˆë‹¤."
    ]
    
    print("\n=== ë‹¤ì¤‘ ë¬¸ì¥ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    for text in multi_sentence_tests:
        result = ResponsePostprocessor.process_summary(text)
        print(f"ì›ë³¸: '{text}'")
        print(f"ì„ íƒëœ ë¬¸ì¥: '{result}'")
        print("---")
    
    print("\n=== ëª…ì‚¬í˜• ë³€í™˜ í…ŒìŠ¤íŠ¸ ===")
    verb_form_tests = [
        "í¬ì¸íŠ¸ ì§€ê¸‰ ë° ì‚¬ìš©ì²˜ ì•ˆë‚´í–ˆìŠµë‹ˆë‹¤",
        "ì‹œìŠ¤í…œ ì¤‘ë‹¨ìœ¼ë¡œ ì¸í•œ ì²˜ë¦¬ ì§€ì—°ë©ë‹ˆë‹¤", 
        "ê³ ê° ë¬¸ì˜ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤",
        "ì¹´ë“œ ë°œê¸‰ ì ˆì°¨ê°€ ì™„ë£Œë©ë‹ˆë‹¤",
        "ìƒë‹´ì›ì´ ì¹œì ˆí•˜ê²Œ ì•ˆë‚´í–ˆìŠµë‹ˆë‹¤",
        "ë¬¸ì œê°€ í•´ê²°ë˜ì—ˆìœ¼ë©° ê³ ê°ì´ ë§Œì¡±í–ˆìŠµë‹ˆë‹¤",
        "ì‹ ì²­ì„œ ê²€í†  í›„ ìŠ¹ì¸ ì²˜ë¦¬ë©ë‹ˆë‹¤",
        "í¬ì¸íŠ¸ ì¶©ì „ì´ ì§„í–‰ë©ë‹ˆë‹¤",
        "ê´€ë ¨ ì„œë¥˜ë¥¼ ì ‘ìˆ˜ë°›ì•˜ìŠµë‹ˆë‹¤",
        "ì‹œìŠ¤í…œ ì ê²€ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤",
        # ìƒˆë¡œ ì¶”ê°€ëœ íŒ¨í„´ë“¤
        "í¬ì¸íŠ¸ê°€ ì§€ê¸‰ë©ë‹ˆë‹¤",
        "ì¹´ë“œê°€ ì‚¬ìš©ë©ë‹ˆë‹¤", 
        "ê²°ì œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
        "ì„œë¹„ìŠ¤ê°€ ì·¨ì†Œë©ë‹ˆë‹¤",
        "ì‹œìŠ¤í…œì´ ì—°ê²°ë©ë‹ˆë‹¤",
        "ì •ë³´ê°€ ë“±ë¡ë©ë‹ˆë‹¤",
        "ë¬¸ì œê°€ í•´ê²°ë˜ì–´ìˆìŠµë‹ˆë‹¤",
        "ê³ ê°ì´ ì´í•´í–ˆê³  ì¶”ê°€ ë¬¸ì˜ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤"
    ]
    
    for text in verb_form_tests:
        converted = ResponsePostprocessor.convert_to_noun_form(text)
        print(f"ì›ë³¸: '{text}'")
        print(f"ë³€í™˜: '{converted}'")
        print("---")
    
    print("\n=== í†µí•© í›„ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (ë™ì‚¬í˜• í¬í•¨) ===")
    verb_response = {
        "summary": "ê³ ê°ì´ ë°”ìš°ì²˜ ì¹´ë“œ ì‚¬ìš©ë²•ì„ ë¬¸ì˜í–ˆê³  ìƒë‹´ì›ì´ ìƒì„¸íˆ ì•ˆë‚´í–ˆìŠµë‹ˆë‹¤",
        "keyword": "ë°”ìš°ì²˜, ì¹´ë“œ, ì‚¬ìš©ë²•, ë¬¸ì˜, ì•ˆë‚´",
        "paragraphs": [
            {
                "summary": "ë°”ìš°ì²˜ ì¹´ë“œ ì‚¬ìš© ì ˆì°¨ì— ëŒ€í•œ ë¬¸ì˜ë¥¼ ì ‘ìˆ˜í–ˆìŠµë‹ˆë‹¤",
                "keyword": "ë°”ìš°ì²˜, ì¹´ë“œ, ì ˆì°¨, ë¬¸ì˜",
                "sentiment": "ë³´í†µ"
            },
            {
                "summary": "ìƒë‹´ì›ì´ ë‹¨ê³„ë³„ë¡œ ìƒì„¸í•˜ê²Œ ì„¤ëª…í–ˆìŠµë‹ˆë‹¤",
                "keyword": "ìƒë‹´, ì„¤ëª…, ë‹¨ê³„ë³„",
                "sentiment": "ì•½í•œê¸ì •"
            },
            {
                "summary": "ê³ ê°ì´ ì´í•´í–ˆê³  ì¶”ê°€ ë¬¸ì˜ëŠ” ì—†ì—ˆìŠµë‹ˆë‹¤", 
                "keyword": "ì´í•´, ì¶”ê°€ë¬¸ì˜",
                "sentiment": "ì•½í•œê¸ì •"
            }
        ]
    }
    
    print("ë™ì‚¬í˜• í¬í•¨ ì›ë³¸:")
    print(json.dumps(verb_response, ensure_ascii=False, indent=2))
    
    print("\nëª…ì‚¬í˜• ë³€í™˜ í›„:")
    processed_verb = ResponsePostprocessor.process_response(verb_response)
    print(json.dumps(processed_verb, ensure_ascii=False, indent=2)) 